{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLO-Rp5vvdcb"
      },
      "source": [
        "# Лабораторная работа 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPDcp7zbvdcd"
      },
      "source": [
        "Tensorflow 2.x\n",
        "\n",
        "1) Подготовка данных\n",
        "\n",
        "2) Использование Keras Model API\n",
        "\n",
        "3) Использование Keras Sequential + Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZoi54Qdvdce"
      },
      "source": [
        "https://www.tensorflow.org/tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlVoSXjEvdce"
      },
      "source": [
        "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
        "\n",
        "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DS184FD2vdce"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_GPU = True\n",
        "device = '/device:GPU:0' if USE_GPU else '/cpu:0'"
      ],
      "metadata": {
        "id": "WX8pKW3DxlGH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPVkLrN_vdcf"
      },
      "source": [
        "# Подготовка данных\n",
        "Загрузите набор данных из предыдущей лабораторной работы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0R2AmaPvdcf",
        "outputId": "f969832c-b1bc-46bc-9112-ae883bef07c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
            "Train data shape:  (49000, 32, 32, 3)\n",
            "Train labels shape:  (49000,) int32\n",
            "Validation data shape:  (1000, 32, 32, 3)\n",
            "Validation labels shape:  (1000,)\n",
            "Test data shape:  (10000, 32, 32, 3)\n",
            "Test labels shape:  (10000,)\n"
          ]
        }
      ],
      "source": [
        "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
        "    \"\"\"\n",
        "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
        "    it for the two-layer neural net classifier. These are the same steps as\n",
        "    we used for the SVM, but condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
        "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10\n",
        "    X_train = np.asarray(X_train, dtype=np.float32)\n",
        "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
        "    X_test = np.asarray(X_test, dtype=np.float32)\n",
        "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = range(num_training, num_training + num_validation)\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = range(num_training)\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = range(num_test)\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean pixel and divide by std\n",
        "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
        "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
        "    X_train = (X_train - mean_pixel) / std_pixel\n",
        "    X_val = (X_val - mean_pixel) / std_pixel\n",
        "    X_test = (X_test - mean_pixel) / std_pixel\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# If there are errors with SSL downloading involving self-signed certificates,\n",
        "# it may be that your Python version was recently installed on the current machine.\n",
        "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
        "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
        "#   ...replacing paths as necessary.\n",
        "\n",
        "# Invoke the above function to get our data.\n",
        "NHW = (0, 1, 2)\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
        "print('Train data shape: ', X_train.shape)\n",
        "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
        "print('Validation data shape: ', X_val.shape)\n",
        "print('Validation labels shape: ', y_val.shape)\n",
        "print('Test data shape: ', X_test.shape)\n",
        "print('Test labels shape: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p19WBfbevdcf"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, X, y, batch_size, shuffle=False):\n",
        "        \"\"\"\n",
        "        Construct a Dataset object to iterate over data X and labels y\n",
        "\n",
        "        Inputs:\n",
        "        - X: Numpy array of data, of any shape\n",
        "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
        "        - batch_size: Integer giving number of elements per minibatch\n",
        "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
        "        \"\"\"\n",
        "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
        "        self.X, self.y = X, y\n",
        "        self.batch_size, self.shuffle = batch_size, shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        N, B = self.X.shape[0], self.batch_size\n",
        "        idxs = np.arange(N)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(idxs)\n",
        "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
        "\n",
        "\n",
        "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
        "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
        "test_dset = Dataset(X_test, y_test, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y55DtKlevdcf",
        "outputId": "7771a29f-3fe3-48f3-c895-ec923348c0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (64, 32, 32, 3) (64,)\n",
            "1 (64, 32, 32, 3) (64,)\n",
            "2 (64, 32, 32, 3) (64,)\n",
            "3 (64, 32, 32, 3) (64,)\n",
            "4 (64, 32, 32, 3) (64,)\n",
            "5 (64, 32, 32, 3) (64,)\n",
            "6 (64, 32, 32, 3) (64,)\n"
          ]
        }
      ],
      "source": [
        "# We can iterate through a dataset like this:\n",
        "for t, (x, y) in enumerate(train_dset):\n",
        "    print(t, x.shape, y.shape)\n",
        "    if t > 5: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1oChNcJvdcg"
      },
      "source": [
        "#  Keras Model Subclassing API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njSHdHoHvdcg"
      },
      "source": [
        "\n",
        "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
        "\n",
        "1) Определить новый класс, который является наследником tf.keras.Model.\n",
        "\n",
        "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
        "\n",
        "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
        "\n",
        "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети.\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQNv1iGlvdcg",
        "outputId": "599db3a8-3321-4cec-df86-8f91001f5252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "class TwoLayerFC(tf.keras.Model):\n",
        "    def __init__(self, hidden_size, num_classes):\n",
        "        super(TwoLayerFC, self).__init__()\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                   kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def test_TwoLayerFC():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = TwoLayerFC(hidden_size, num_classes)\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_TwoLayerFC()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgRf7rAlvdcg"
      },
      "source": [
        "Реализуйте трехслойную CNN для вашей задачи классификации.\n",
        "\n",
        "Архитектура сети:\n",
        "    \n",
        "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
        "2. Функция активации ReLU\n",
        "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
        "4. Функция активации ReLU\n",
        "5. Полносвязный слой\n",
        "6. Функция активации Softmax\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "68L07xt6vdcg"
      },
      "outputs": [],
      "source": [
        "class ThreeLayerConvNet(tf.keras.Model):\n",
        "    def __init__(self, channel_1, channel_2, num_classes):\n",
        "        super(ThreeLayerConvNet, self).__init__()\n",
        "        ########################################################################\n",
        "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
        "        # should instantiate layer objects to be used in the forward pass.     #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=channel_1, kernel_size=(5,5),\n",
        "                                            padding='same', activation='relu',\n",
        "                                            kernel_initializer=initializer)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=channel_2, kernel_size=(3,3),\n",
        "                                            padding='same', activation='relu',\n",
        "                                            kernel_initializer=initializer)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                                        kernel_initializer=initializer)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        scores = None\n",
        "        ########################################################################\n",
        "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
        "        # should use the layer objects defined in the __init__ method.         #\n",
        "        ########################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        scores = self.conv1(x)\n",
        "        scores = self.conv2(scores)\n",
        "        scores = self.flatten(scores)\n",
        "        scores = self.fc(scores)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ########################################################################\n",
        "        #                           END OF YOUR CODE                           #\n",
        "        ########################################################################\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU8qNg0Jvdch",
        "outputId": "890bf391-84b5-4120-a780-3a48914d75e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "def test_ThreeLayerConvNet():\n",
        "    channel_1, channel_2, num_classes = 12, 8, 10\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "    with tf.device(device):\n",
        "        x = tf.zeros((64, 3, 32, 32))\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_ThreeLayerConvNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th1VbMkCvdch"
      },
      "source": [
        "Пример реализации процесса обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4u6IIQZXvdch"
      },
      "outputs": [],
      "source": [
        "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
        "    \"\"\"\n",
        "    Simple training loop for use with models defined using tf.keras. It trains\n",
        "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
        "    accuracy on the CIFAR-10 validation set.\n",
        "\n",
        "    Inputs:\n",
        "    - model_init_fn: A function that takes no parameters; when called it\n",
        "      constructs the model we want to train: model = model_init_fn()\n",
        "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
        "      constructs the Optimizer object we will use to optimize the model:\n",
        "      optimizer = optimizer_init_fn()\n",
        "    - num_epochs: The number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints progress during trainingn\n",
        "    \"\"\"\n",
        "    with tf.device(device):\n",
        "\n",
        "\n",
        "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "        model = model_init_fn()\n",
        "        optimizer = optimizer_init_fn()\n",
        "\n",
        "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
        "\n",
        "        t = 0\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
        "            train_loss.reset_state()\n",
        "            train_accuracy.reset_state()\n",
        "\n",
        "            for x_np, y_np in train_dset:\n",
        "                with tf.GradientTape() as tape:\n",
        "\n",
        "                    # Use the model function to build the forward pass.\n",
        "                    scores = model(x_np, training=is_training)\n",
        "                    loss = loss_fn(y_np, scores)\n",
        "\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "                    # Update the metrics\n",
        "                    train_loss.update_state(loss)\n",
        "                    train_accuracy.update_state(y_np, scores)\n",
        "\n",
        "                    if t % print_every == 0:\n",
        "                        val_loss.reset_state()\n",
        "                        val_accuracy.reset_state()\n",
        "                        for test_x, test_y in val_dset:\n",
        "                            # During validation at end of epoch, training set to False\n",
        "                            prediction = model(test_x, training=False)\n",
        "                            t_loss = loss_fn(test_y, prediction)\n",
        "\n",
        "                            val_loss.update_state(t_loss)\n",
        "                            val_accuracy.update_state(test_y, prediction)\n",
        "\n",
        "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
        "                        print (template.format(t, epoch+1,\n",
        "                                             train_loss.result(),\n",
        "                                             train_accuracy.result()*100,\n",
        "                                             val_loss.result(),\n",
        "                                             val_accuracy.result()*100))\n",
        "                    t += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y33oJb0vdch",
        "outputId": "3016e424-dfef-4693-8db4-b2515730359b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.730674982070923, Accuracy: 12.5, Val Loss: 2.834641456604004, Val Accuracy: 13.0\n",
            "Iteration 100, Epoch 1, Loss: 2.2534189224243164, Accuracy: 27.70730209350586, Val Loss: 1.8840396404266357, Val Accuracy: 37.400001525878906\n",
            "Iteration 200, Epoch 1, Loss: 2.081246852874756, Accuracy: 31.96517562866211, Val Loss: 1.8338268995285034, Val Accuracy: 40.5\n",
            "Iteration 300, Epoch 1, Loss: 2.007025718688965, Accuracy: 33.98567199707031, Val Loss: 1.8575338125228882, Val Accuracy: 37.400001525878906\n",
            "Iteration 400, Epoch 1, Loss: 1.9383149147033691, Accuracy: 35.925811767578125, Val Loss: 1.7416967153549194, Val Accuracy: 42.5\n",
            "Iteration 500, Epoch 1, Loss: 1.8936060667037964, Accuracy: 36.9323844909668, Val Loss: 1.6745445728302002, Val Accuracy: 41.10000228881836\n",
            "Iteration 600, Epoch 1, Loss: 1.8632272481918335, Accuracy: 37.79378128051758, Val Loss: 1.6893975734710693, Val Accuracy: 41.5\n",
            "Iteration 700, Epoch 1, Loss: 1.836732029914856, Accuracy: 38.534236907958984, Val Loss: 1.641034722328186, Val Accuracy: 43.39999771118164\n"
          ]
        }
      ],
      "source": [
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "print_every = 100\n",
        "\n",
        "def model_init_fn():\n",
        "    return TwoLayerFC(hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyYxULhpvdch"
      },
      "source": [
        "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 .\n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
        "\n",
        "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvfm9pZVvdch",
        "outputId": "a7eb2223-f046-435a-a12c-32fb0be456b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.6038882732391357, Accuracy: 7.8125, Val Loss: 8.987314224243164, Val Accuracy: 8.800000190734863\n",
            "Iteration 100, Epoch 1, Loss: 2.3389625549316406, Accuracy: 22.400989532470703, Val Loss: 1.9214643239974976, Val Accuracy: 32.70000076293945\n",
            "Iteration 200, Epoch 1, Loss: 2.080897331237793, Accuracy: 28.762439727783203, Val Loss: 1.7189702987670898, Val Accuracy: 39.89999771118164\n",
            "Iteration 300, Epoch 1, Loss: 1.9515777826309204, Accuracy: 32.194766998291016, Val Loss: 1.6251015663146973, Val Accuracy: 42.0\n",
            "Iteration 400, Epoch 1, Loss: 1.8531453609466553, Accuracy: 35.13871383666992, Val Loss: 1.5416910648345947, Val Accuracy: 45.400001525878906\n",
            "Iteration 500, Epoch 1, Loss: 1.7852287292480469, Accuracy: 37.29104232788086, Val Loss: 1.4670937061309814, Val Accuracy: 47.5\n",
            "Iteration 600, Epoch 1, Loss: 1.7368277311325073, Accuracy: 38.857112884521484, Val Loss: 1.4302096366882324, Val Accuracy: 48.400001525878906\n",
            "Iteration 700, Epoch 1, Loss: 1.6954145431518555, Accuracy: 40.1435432434082, Val Loss: 1.395768404006958, Val Accuracy: 52.20000076293945\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1, channel_2, num_classes = 32, 16, 10\n",
        "\n",
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hF--zIaJvdci"
      },
      "source": [
        "# Использование Keras Sequential API для реализации последовательных моделей.\n",
        "\n",
        "Пример для полносвязной сети:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrJkthIVvdci",
        "outputId": "7b80a98a-5055-4006-abb9-e1e5e2fca8b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.215442419052124, Accuracy: 4.6875, Val Loss: 2.7577574253082275, Val Accuracy: 13.09999942779541\n",
            "Iteration 100, Epoch 1, Loss: 2.2206757068634033, Accuracy: 29.331684112548828, Val Loss: 1.9204566478729248, Val Accuracy: 37.900001525878906\n",
            "Iteration 200, Epoch 1, Loss: 2.064004421234131, Accuracy: 32.96797180175781, Val Loss: 1.8694486618041992, Val Accuracy: 40.20000076293945\n",
            "Iteration 300, Epoch 1, Loss: 1.9922564029693604, Accuracy: 34.6034049987793, Val Loss: 1.8820695877075195, Val Accuracy: 37.70000076293945\n",
            "Iteration 400, Epoch 1, Loss: 1.9234411716461182, Accuracy: 36.27649688720703, Val Loss: 1.7320261001586914, Val Accuracy: 42.89999771118164\n",
            "Iteration 500, Epoch 1, Loss: 1.8797262907028198, Accuracy: 37.337825775146484, Val Loss: 1.6698484420776367, Val Accuracy: 42.69999694824219\n",
            "Iteration 600, Epoch 1, Loss: 1.851555585861206, Accuracy: 38.18375778198242, Val Loss: 1.717450737953186, Val Accuracy: 41.5\n",
            "Iteration 700, Epoch 1, Loss: 1.8267345428466797, Accuracy: 38.8306884765625, Val Loss: 1.6492607593536377, Val Accuracy: 42.89999771118164\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    input_shape = (32, 32, 3)\n",
        "    hidden_layer_size, num_classes = 4000, 10\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    layers = [\n",
        "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
        "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
        "                              kernel_initializer=initializer),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                              kernel_initializer=initializer),\n",
        "    ]\n",
        "    model = tf.keras.Sequential(layers)\n",
        "    return model\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKzBQYr_vdci"
      },
      "source": [
        "Альтернативный менее гибкий способ обучения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2BHRWuyvdci",
        "outputId": "cc8f9383-05bb-429c-86cd-f8655fee1bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 2.0172 - sparse_categorical_accuracy: 0.3349 - val_loss: 1.6557 - val_sparse_categorical_accuracy: 0.4530\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.6297 - sparse_categorical_accuracy: 0.4354\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.638246774673462, 0.43639999628067017]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lx2z3Q6avdci"
      },
      "source": [
        "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTGdOGCmvdci",
        "outputId": "6da1afec-e954-4260-80bb-236bdb10bbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 2.3339896202087402, Accuracy: 9.375, Val Loss: 2.353342294692993, Val Accuracy: 9.899999618530273\n",
            "Iteration 100, Epoch 1, Loss: 2.310960531234741, Accuracy: 10.767326354980469, Val Loss: 2.274129629135132, Val Accuracy: 12.399999618530273\n",
            "Iteration 200, Epoch 1, Loss: 2.2839717864990234, Accuracy: 13.020833015441895, Val Loss: 2.230102777481079, Val Accuracy: 17.899999618530273\n",
            "Iteration 300, Epoch 1, Loss: 2.262726068496704, Accuracy: 15.214908599853516, Val Loss: 2.197784662246704, Val Accuracy: 21.100000381469727\n",
            "Iteration 400, Epoch 1, Loss: 2.242192506790161, Accuracy: 17.26932716369629, Val Loss: 2.161949872970581, Val Accuracy: 22.899999618530273\n",
            "Iteration 500, Epoch 1, Loss: 2.226245641708374, Accuracy: 18.516094207763672, Val Loss: 2.1335840225219727, Val Accuracy: 25.400001525878906\n",
            "Iteration 600, Epoch 1, Loss: 2.210104465484619, Accuracy: 19.774333953857422, Val Loss: 2.107278347015381, Val Accuracy: 26.0\n",
            "Iteration 700, Epoch 1, Loss: 2.194254159927368, Accuracy: 20.778352737426758, Val Loss: 2.0799612998962402, Val Accuracy: 27.200000762939453\n"
          ]
        }
      ],
      "source": [
        "def model_init_fn():\n",
        "    model = None\n",
        "    ############################################################################\n",
        "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    model = tf.keras.Sequential([\n",
        "      # Первый сверточный слой\n",
        "      tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "      # Второй сверточный слой\n",
        "      tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "      # Полносвязный слой с relu активацией\n",
        "      tf.keras.layers.Dense(1024, activation='relu'),\n",
        "      # Выходной слой с softmax активацией\n",
        "      tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                            END OF YOUR CODE                              #\n",
        "    ############################################################################\n",
        "    return model\n",
        "\n",
        "learning_rate = 5e-4\n",
        "def optimizer_init_fn():\n",
        "    optimizer = None\n",
        "    ############################################################################\n",
        "    # TODO: Complete the implementation of model_fn.                           #\n",
        "    ############################################################################\n",
        "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "\n",
        "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "    ############################################################################\n",
        "    #                           END OF YOUR CODE                               #\n",
        "    ############################################################################\n",
        "    return optimizer\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKswdmfzvdci",
        "outputId": "52cb25a4-f56a-4452-ceef-f9fde95fbcf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 1.8532 - sparse_categorical_accuracy: 0.3395 - val_loss: 1.4166 - val_sparse_categorical_accuracy: 0.4890\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.4355 - sparse_categorical_accuracy: 0.4747\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.441324234008789, 0.4722000062465668]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model = model_init_fn()\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
        "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
        "model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_ykWxPDvdci"
      },
      "source": [
        "# Использование Keras Functional API\n",
        "\n",
        "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры.\n",
        "\n",
        "Ниже представлен пример для полносвязной сети."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf0lS8uFvdci",
        "outputId": "e96f9efc-c6ad-4f02-f48e-a73e8cfa9f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 10)\n"
          ]
        }
      ],
      "source": [
        "def two_layer_fc_functional(input_shape, hidden_size, num_classes):\n",
        "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
        "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
        "                                 kernel_initializer=initializer)(flattened_inputs)\n",
        "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
        "                             kernel_initializer=initializer)(fc1_output)\n",
        "\n",
        "    # Instantiate the model given inputs and outputs.\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
        "    return model\n",
        "\n",
        "def test_two_layer_fc_functional():\n",
        "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
        "    input_size, hidden_size, num_classes = 50, 42, 10\n",
        "    input_shape = (50,)\n",
        "\n",
        "    x = tf.zeros((64, input_size))\n",
        "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "    with tf.device(device):\n",
        "        scores = model(x)\n",
        "        print(scores.shape)\n",
        "\n",
        "test_two_layer_fc_functional()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMKxwt7hvdci",
        "outputId": "b1f8e7db-ed95-4337-f0b9-515bca002099"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.1890501976013184, Accuracy: 7.8125, Val Loss: 2.9843106269836426, Val Accuracy: 9.800000190734863\n",
            "Iteration 100, Epoch 1, Loss: 2.2391374111175537, Accuracy: 28.7592830657959, Val Loss: 1.901845097541809, Val Accuracy: 38.5\n",
            "Iteration 200, Epoch 1, Loss: 2.070812225341797, Accuracy: 32.77363204956055, Val Loss: 1.8534682989120483, Val Accuracy: 40.400001525878906\n",
            "Iteration 300, Epoch 1, Loss: 1.9969618320465088, Accuracy: 34.42171859741211, Val Loss: 1.8813104629516602, Val Accuracy: 36.89999771118164\n",
            "Iteration 400, Epoch 1, Loss: 1.9304864406585693, Accuracy: 36.03881072998047, Val Loss: 1.7551515102386475, Val Accuracy: 39.79999923706055\n",
            "Iteration 500, Epoch 1, Loss: 1.886325478553772, Accuracy: 37.02594757080078, Val Loss: 1.6786789894104004, Val Accuracy: 42.20000076293945\n",
            "Iteration 600, Epoch 1, Loss: 1.8565772771835327, Accuracy: 37.88217544555664, Val Loss: 1.6796510219573975, Val Accuracy: 42.599998474121094\n",
            "Iteration 700, Epoch 1, Loss: 1.8307806253433228, Accuracy: 38.532005310058594, Val Loss: 1.636837124824524, Val Accuracy: 43.900001525878906\n"
          ]
        }
      ],
      "source": [
        "input_shape = (32, 32, 3)\n",
        "hidden_size, num_classes = 4000, 10\n",
        "learning_rate = 1e-2\n",
        "\n",
        "def model_init_fn():\n",
        "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz3an4eLvdcj"
      },
      "source": [
        "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут).\n",
        "\n",
        "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
        "\n",
        "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQHpVYThvdcj",
        "outputId": "db277fce-7932-4856-d294-42fa1a6b079e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Epoch 1, Loss: 3.6561079025268555, Accuracy: 9.375, Val Loss: 2.998950242996216, Val Accuracy: 12.199999809265137\n",
            "Iteration 700, Epoch 1, Loss: 1.5161646604537964, Accuracy: 46.62535858154297, Val Loss: 1.1695425510406494, Val Accuracy: 61.79999542236328\n",
            "Iteration 1400, Epoch 2, Loss: 1.0199286937713623, Accuracy: 63.94684982299805, Val Loss: 0.8856332898139954, Val Accuracy: 69.5\n",
            "Iteration 2100, Epoch 3, Loss: 0.8502669334411621, Accuracy: 69.88961029052734, Val Loss: 0.7688243389129639, Val Accuracy: 73.4000015258789\n",
            "Iteration 2800, Epoch 4, Loss: 0.7535499930381775, Accuracy: 73.43439483642578, Val Loss: 0.7057284116744995, Val Accuracy: 76.20000457763672\n",
            "Iteration 3500, Epoch 5, Loss: 0.688689649105072, Accuracy: 75.71867370605469, Val Loss: 0.6174358129501343, Val Accuracy: 78.30000305175781\n",
            "Iteration 4200, Epoch 6, Loss: 0.6398293972015381, Accuracy: 77.73753356933594, Val Loss: 0.6216412782669067, Val Accuracy: 78.19999694824219\n",
            "Iteration 4900, Epoch 7, Loss: 0.5924858450889587, Accuracy: 79.20594024658203, Val Loss: 0.6103991270065308, Val Accuracy: 80.0999984741211\n",
            "Iteration 5600, Epoch 8, Loss: 0.542762041091919, Accuracy: 81.33499145507812, Val Loss: 0.7913044095039368, Val Accuracy: 72.0\n",
            "Iteration 6300, Epoch 9, Loss: 0.5114806294441223, Accuracy: 82.23446655273438, Val Loss: 0.5253378748893738, Val Accuracy: 82.30000305175781\n",
            "Iteration 7000, Epoch 10, Loss: 0.46818894147872925, Accuracy: 83.86389923095703, Val Loss: 0.48210254311561584, Val Accuracy: 83.70000457763672\n"
          ]
        }
      ],
      "source": [
        "class CustomConvNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomConvNet, self).__init__()\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
        "        # Блок 1\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3,3), padding='same', kernel_initializer=initializer)\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu1 = tf.keras.layers.ReLU()\n",
        "        # Блок 2\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3,3), padding='same', kernel_initializer=initializer)\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu2 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D((2,2))\n",
        "        self.dropout1 = tf.keras.layers.Dropout(0.25)\n",
        "        # Блок 3\n",
        "        self.conv3 = tf.keras.layers.Conv2D(128, (3,3), padding='same', kernel_initializer=initializer)\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu3 = tf.keras.layers.ReLU()\n",
        "        # Блок 4\n",
        "        self.conv4 = tf.keras.layers.Conv2D(128, (3,3), padding='same', kernel_initializer=initializer)\n",
        "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu4 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.pool2 = tf.keras.layers.MaxPool2D((2,2))\n",
        "        self.dropout2 = tf.keras.layers.Dropout(0.35)\n",
        "        # Блок 5\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (3,3), padding='same', kernel_initializer=initializer)\n",
        "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
        "        self.relu5 = tf.keras.layers.ReLU()\n",
        "\n",
        "        self.pool3 = tf.keras.layers.MaxPool2D((2,2))\n",
        "        self.dropout3 = tf.keras.layers.Dropout(0.4)\n",
        "\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.fc1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=initializer)\n",
        "        self.bnfc = tf.keras.layers.BatchNormalization()\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "        self.dropout_fc = tf.keras.layers.Dropout(0.5)\n",
        "        self.fc_out = tf.keras.layers.Dense(10, activation='softmax', kernel_initializer=initializer)\n",
        "\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        ############################################################################\n",
        "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
        "        ############################################################################\n",
        "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x =  self.relu2(x)\n",
        "        x = self.pool1(x)\n",
        "        if training:\n",
        "          x = self.dropout1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.pool2(x)\n",
        "        if training:\n",
        "          x = self.dropout2(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.pool3(x)\n",
        "        if training:\n",
        "          x = self.dropout3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bnfc(x)\n",
        "        x = self.relu(x)\n",
        "        if training:\n",
        "          x = self.dropout_fc(x)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
        "        ############################################################################\n",
        "        #                            END OF YOUR CODE                              #\n",
        "        ############################################################################\n",
        "        return x\n",
        "\n",
        "\n",
        "print_every = 700\n",
        "num_epochs = 10\n",
        "\n",
        "model = CustomConvNet()\n",
        "\n",
        "def model_init_fn():\n",
        "    return CustomConvNet()\n",
        "\n",
        "def optimizer_init_fn():\n",
        "    learning_rate = 1e-3\n",
        "    return tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удалось достичь точности на вадидационной выборке в 83.7%"
      ],
      "metadata": {
        "id": "vVgIxcHFFu7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализована улучшенная сверточная сеть, включающая:\n",
        "- 5 свёрточных слоёв\n",
        "- BatchNormalization после каждого сверточного слоя\n",
        "- MaxPooling слои\n",
        "- Dropout для регуляризации\n",
        "- Полносвязный блок: Dense(512) + - Dropout\n",
        "- Выходной слой Softmax\n",
        "Архитектура похожа на VGG\n",
        "CustomConvNet показала наилучшую точность благодаря глубокой архитектуре, BatchNorm и Dropout."
      ],
      "metadata": {
        "id": "QM0Qc9HmDpim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "При одинаковых гирерпараметрах были протестированы оптимизаторы:  Adam, SGD, RMSprop. SGD показал наихудшие результаты - за 10 эпох точность на валидационной выборке была в районе 69%. Adam и RMSprop показали примерно одинаковые результаты, однако Adam был немножко точнее."
      ],
      "metadata": {
        "id": "W3q7tLTEEcUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наилучший результат был получен пи learning rate = 1e-3, при 1e-4 наблюдалась более медленная сходимость и меньшая точность модели после 10 эпох обучения (78,3%)"
      ],
      "metadata": {
        "id": "jJdLUgRwGIC_"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}